{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_latent_space import BRepDS, BRepFaceAutoencoder, BRepFaceEncoder, implicit_part_to_data, ImplicitPart, ImplicitDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/media/ben/Data/cad'\n",
    "model_checkpoint_path = data_root + '/BRepFaceAutoencoder_64_1024_4.ckpt'\n",
    "cube_path = data_root + '/cubes/cube.x_t'\n",
    "long_cube_path = data_root + '/cubes/long_cube.x_t'\n",
    "angled_cube_path = data_root + '/cubes/angled_cube.x_t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.79950714111328\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from chamferdist import ChamferDistance\n",
    "\n",
    "source_cloud = torch.randn(1, 100, 3).cuda()\n",
    "target_cloud = torch.randn(1, 50, 3).cuda()\n",
    "\n",
    "chamferDist = ChamferDistance()\n",
    "\n",
    "dist_forward = chamferDist(source_cloud, target_cloud)\n",
    "print(dist_forward.detach().cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.7995, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipart = ImplicitPart(cube_path, 10, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipart = ImplicitPart(cube_path, 10, 100, True)\n",
    "data = implicit_part_to_data(ipart, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HetData(bounding_box=[2, 3], face_surfaces=[6, 5], face_surface_parameters=[6, 11], face_surface_flipped=[6], loop_types=[6, 10], loop_length=[6], edge_curves=[12, 3], edge_curve_parameters=[12, 11], edge_curve_flipped=[12], edge_length=[12], vertex_positions=[8, 3], face_to_face=[3, 12], face_to_loop=[2, 6], loop_to_edge=[2, 24], edge_to_vertex=[2, 24], loop_to_vertex=[2, 0], edge_to_vertex_is_start=[24], loop_to_edge_flipped=[24], surface_bounds=[6, 2, 2], surface_coords=[6, 10, 2], surface_samples=[6, 10, 7], curve_bounds=[12, 2], curve_samples=[12, 4, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = BRepFaceAutoencoder(64,1024,4)\n",
    "ckpt = torch.load(model_checkpoint_path)\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/automate/lib/python3.9/site-packages/torch/functional.py:1069: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = BRepFaceAutoencoder(64,1024,4)\n",
    "ckpt = torch.load(model_checkpoint_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "n_faces = 6\n",
    "N = 50\n",
    "line = torch.linspace(-0.1,1.1,N)\n",
    "grid = torch.cartesian_prod(line, line)\n",
    "grids = grid.repeat(n_faces,1)\n",
    "indices = torch.arange(n_faces).repeat_interleave(N*N, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data, grids, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(pred[:,:3].detach().numpy(), c=pred[:,3].detach().numpy(), shading={'point_size':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_part = Part(cube_path, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pspy import Part, PartOptions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xyz = pred[:,:3].detach().numpy()\n",
    "pred_m = pred[:,3].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2384077, 1.2069366, 1.2218487], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xyz.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import SamplePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SamplePoints(6*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data as TGData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = PartOptions()\n",
    "opts.normalize = True\n",
    "angled_part = Part(angled_cube_path, opts)\n",
    "angled_V = torch.from_numpy(2*angled_part.mesh.V)\n",
    "angled_F = torch.from_numpy(angled_part.mesh.F).T.long()\n",
    "angled_data = TGData(pos=angled_V, face=angled_F)\n",
    "sampler(angled_data)\n",
    "target_pc = angled_data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(pos=[6000, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5508,  0.2843, -0.7887],\n",
       "        [-0.6832,  0.5774,  0.0289],\n",
       "        [-0.3737,  0.5774, -0.0206],\n",
       "        ...,\n",
       "        [ 0.9981, -0.1620, -0.7818],\n",
       "        [ 0.4532,  0.5774, -0.3701],\n",
       "        [-1.0000, -0.5343, -0.6798]], dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angled_data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = mp.plot(2*angled_part.mesh.V, angled_part.mesh.F, return_plot=True)\n",
    "plot.add_points(target_pc.numpy(), shading={'point_size':0.3, 'point_color':'red'})\n",
    "plot.add_points(pred_xyz, c=pred_m, shading={'point_size':.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "angled = ImplicitPart(angled_cube_path, 1000, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pc = np.stack(angled.surface_samples)[:,:,3].reshape((-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(target_pc, shading={'point_size':.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chamferdist import ChamferDistance\n",
    "\n",
    "#source_cloud = torch.randn(1, 100, 3).cuda()\n",
    "#target_cloud = torch.randn(1, 50, 3).cuda()\n",
    "\n",
    "\n",
    "\n",
    "dist_forward = chamferDist(source_cloud, target_cloud)\n",
    "print(dist_forward.detach().cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "chamferDist = ChamferDistance()\n",
    "opts = PartOptions()\n",
    "opts.normalize = True\n",
    "angled_part = Part(angled_cube_path, opts)\n",
    "angled_V = torch.from_numpy(2*angled_part.mesh.V)\n",
    "angled_F = torch.from_numpy(angled_part.mesh.F).T.long()\n",
    "angled_data = TGData(pos=angled_V, face=angled_F)\n",
    "sampler(angled_data)\n",
    "target_pc = angled_data.pos\n",
    "target = target_pc.unsqueeze(0).float().cuda()\n",
    "\n",
    "ipart = ImplicitPart(cube_path, 10, 100, True)\n",
    "data = implicit_part_to_data(ipart, 10).cuda()\n",
    "data.face_surfaces = data.face_surfaces.float()\n",
    "data.face_surfaces.requires_grad = True\n",
    "data.edge_curves = data.edge_curves.float()\n",
    "data.edge_curves.requires_grad = True\n",
    "data.vertex_positions.requires_grad = True\n",
    "data.face_surface_parameters.requires_grad = True\n",
    "data.edge_curve_parameters.requires_grad = True\n",
    "\n",
    "model = BRepFaceAutoencoder(64,1024,4)\n",
    "ckpt = torch.load(model_checkpoint_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "n_faces = 6\n",
    "N = 50\n",
    "line = torch.linspace(-0.1,1.1,N)\n",
    "grid = torch.cartesian_prod(line, line)\n",
    "grids = grid.repeat(n_faces,1)\n",
    "indices = torch.arange(n_faces).repeat_interleave(N*N, dim=0)\n",
    "\n",
    "\n",
    "model = model.cuda()\n",
    "grids = grids.cuda()\n",
    "indices = indices.cuda()\n",
    "\n",
    "opt = torch.optim.SGD(\n",
    "    [\n",
    "        data.face_surfaces,\n",
    "        data.edge_curves,\n",
    "        data.edge_curve_parameters,\n",
    "        data.vertex_positions,\n",
    "        data.face_surface_parameters\n",
    "    ], \n",
    "    lr=0.001, \n",
    "    momentum=0.5)\n",
    "\n",
    "losses = []\n",
    "predictions = []\n",
    "\n",
    "num_iters = 1000\n",
    "\n",
    "for iter in tqdm(range(num_iters)):\n",
    "    opt.zero_grad()\n",
    "    pred = model(data, grids, indices)\n",
    "    pred_xyz = pred[:,:3].unsqueeze(0).float()\n",
    "    pred_m = pred[:,3].unsqueeze(0).float()\n",
    "    loss = chamferDist(pred_xyz, target) + chamferDist(target, pred_xyz)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    losses.append(loss.detach().item())\n",
    "    predictions.append((pred_xyz.detach().cpu().numpy(), pred_m.detach().cpu().numpy()))\n",
    "    #print(loss)\n",
    "plt.plot(losses)\n",
    "i = 0\n",
    "plot1 = mp.plot(\n",
    "    predictions[i][0][0,:,:],\n",
    "    c=predictions[i][1][0,:],\n",
    "    shading={'point_size':0.1},\n",
    "    return_plot = True)\n",
    "plot1.add_points(target_pc.numpy(), shading={'point_size':0.1, 'point_color':'red'})\n",
    "\n",
    "i = num_iters - 1\n",
    "plot2 =mp.plot(\n",
    "    predictions[i][0][0,:,:],\n",
    "    c=predictions[i][1][0,:],\n",
    "    shading={'point_size':0.1},\n",
    "    return_plot=True)\n",
    "plot2.add_points(target_pc.numpy(), shading={'point_size':0.1, 'point_color':'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "mp.plot(\n",
    "    predictions[i][0][0,:,:],\n",
    "    c=predictions[i][1][0,:],\n",
    "    shading={'point_size':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data, grids, indices)\n",
    "pred_xyz = pred[:,:3].unsqueeze(0).float()\n",
    "pred_m = pred[:,3].unsqueeze(0).float()\n",
    "loss = chamferDist(pred_xyz, target) + chamferDist(target, pred_xyz)\n",
    "#loss.backward()\n",
    "#opt.step()\n",
    "#losses.append(loss.detach().item())\n",
    "#params.append(data.face_surface_parameters.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.face_surface_parameters.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = num_iters - 1\n",
    "plot2 =mp.plot(\n",
    "    predictions[i][0][0,:,:],\n",
    "    c=predictions[i][1][0,:],\n",
    "    shading={'point_size':0.1},\n",
    "    return_plot=True)\n",
    "plot2.add_points(target_pc.numpy(), shading={'point_size':0.1, 'point_color':'red'})\n",
    "plot2.add_mesh(angled_V.numpy(), angled_F.T.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1644.8860, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chamferDist(pred_xyz.unsqueeze(0).float(), target_pc.unsqueeze(0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff508123a60>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d348aabc84c65cf5454f47dd42764ee2f97f6b03d2b3fb68e7398f050dcdb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
